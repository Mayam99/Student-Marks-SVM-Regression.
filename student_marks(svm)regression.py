# -*- coding: utf-8 -*-
"""Student Marks(SVM)Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vykS77ZChz1_9f8WX4oHwKL6l9sA4IDb

#Predicting Student Marks Using SVM Regression with Hyper-Parameter Tuning
###In this notebook, we delve into a comprehensive step-by-step approach for predicting student marks using Support Vector Machine (SVM) Regression. The dataset used for this analysis, sourced from Kaggle, provides insights into student performance based on various factors, making it ideal for implementing regression techniques.

##Project Objectives
###Our main objectives are:

* Implementing SVM Regression: To model the relationship between student marks and the influencing factors within the dataset.
* Hyper-Parameter Tuning: To optimize the model’s performance by fine-tuning key parameters, including the kernel type, regularization (C), and epsilon (ε) values.
##Key Steps

###The project includes data preprocessing, exploratory data analysis, SVM regression model setup, and hyper-parameter tuning using cross-validation. Each step will provide valuable insights into handling regression tasks in machine learning, from data preparation to model evaluation.
"""

# Data manipulation and visualization
import pandas as pd # It imports the pandas library and assigns it the alias "pd" for easier use.
import numpy as np # It brings in a tool called numpy, nicknamed "np", to help with number crunching in your code.
import matplotlib.pyplot as plt # Import libraries for creating visualizations, aliased as plt.
import seaborn as sns  # Import libraries for creating visualizations, aliased as sns.

# Machine learning and model evaluation
from sklearn.model_selection import train_test_split, GridSearchCV # It imports functions for splitting data and tuning model hyperparameters for better performance evaluation.
from sklearn.svm import SVR # It imports the Support Vector Regression (SVR) model for performing regression tasks using support vector machines.
from sklearn.preprocessing import StandardScaler # It imports the StandardScaler to standardize features by removing the mean and scaling to unit variance.
from sklearn.metrics import mean_squared_error, r2_score # It imports functions to calculate Mean Squared Error (MSE) and R-squared (R2) for regression model evaluation.

df = pd.read_csv('Student_Marks (1).csv')  #Loads the data from the CSV file into a pandas DataFrame named df.

df.head() #Displays the first 5 rows of the DataFrame df.

df.info() # It prints a concise summary of the DataFrame, including data types, non-null values, and memory usage.

df.isnull().sum()

"""##We can see there is no null values in the dataframe."""

df.describe()

# Visualize correlations (if applicable)
sns.heatmap(df.corr(), annot=True, cmap='viridis')
plt.title('Correlation Matrix')
plt.show()

# Separate features and target variable
X = df.drop('Marks', axis=1)
y = df['Marks']
# It separates the dataset into features (X) by excluding the 'price' column and assigns 'price' as the target variable (y).

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)
# It splits the data into training and testing sets (80% train, 20% test) with a fixed random seed for reproducibility.

svr = SVR()
svr = svr.fit(X_train, y_train)

# Predictions and evaluation
y_pred = svr.predict(X_test)
print("R2 Score:", r2_score(y_test, y_pred))
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))

param_grid = {
    'kernel': ['linear', 'poly', 'rbf'],
    'C': [0.1, 1, 10, 100],
    'epsilon': [0.01, 0.1, 0.5, 1]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(SVR(), param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best parameters and model evaluation
best_svr = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)
y_pred_tuned = best_svr.predict(X_test)
print("Tuned R2 Score:", r2_score(y_test, y_pred_tuned))
print("Tuned Mean Squared Error:", mean_squared_error(y_test, y_pred_tuned))

# Plotting actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_tuned, color='blue', label='Predicted')
plt.plot(y_test, y_test, color='red', label='Actual')
plt.xlabel('Actual Marks')
plt.ylabel('Predicted Marks')
plt.legend()
plt.title('Actual vs. Predicted Marks')
plt.show()

